{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pendahuluan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import neurolab as nl\n",
    "plt.xkcd() # biar lucu\n",
    "plt.style.use('ggplot') # karena saya pengguna R juga biar bagus, Bro plotnya!\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single layer neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* collection od artificial neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sebagai classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teks = np.loadtxt('./data/data_nn_sederhana.txt')\n",
    "teks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = teks[:, :2]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = teks[:,2:]\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisasi data\n",
    "plt.scatter(data[:,0], data[:,1]);\n",
    "plt.xlabel('Dimensi 1');\n",
    "plt.ylabel('Dimensi 2');\n",
    "plt.title('Data input');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit1_min, fit1_maks = data[:,0].min(),data[:,0].max()\n",
    "fi2_min, fit2_maks = data[:,1].min(), data[:,1].max()\n",
    "output = label.shape[1]\n",
    "\n",
    "fit1 = [fit1_min, fit1_maks]\n",
    "fit2 = [fit2_min, fit2_maks]\n",
    "\n",
    "snn = nl.net.newp([fit1,fit2], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training \n",
    "error_progress = snn.train(data, label, epochs=100, show=20, lr=.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(error_progress);\n",
    "plt.xlabel('Jumlah epochs');\n",
    "plt.ylabel('Training error');\n",
    "plt.title(\"Training error progress\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Testing Data:\\n')\n",
    "testing_data = [[0.3, 4.2], [4.3, 0.5], [4.6, 8]]\n",
    "for i in testing_data:\n",
    "    print(i, '==>', snn.sim([i])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-layer neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sebagai regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "berdasarkan $y = 3x^{2} + 5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nilai_min = -20\n",
    "nilai_maks = 20\n",
    "jumlah_titik = 140\n",
    "\n",
    "x = np.linspace(nilai_min, nilai_maks, jumlah_titik)\n",
    "y = 3*np.square(x) + 5\n",
    "\n",
    "# normalisasi untuk efisiensi\n",
    "y /= np.linalg.norm(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = x.reshape(jumlah_titik,1)\n",
    "label = y.reshape(jumlah_titik,1)\n",
    "\n",
    "plt.scatter(data, label);\n",
    "plt.xlabel('$x$');\n",
    "plt.ylabel('$y$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 neuron di hidden layer 1, 6 neuron di hidden layer 2, 1 neuron output \n",
    "mlnn = nl.net.newff([[nilai_min, nilai_maks]], [10,6,1])\n",
    "\n",
    "# menggunakan gradien descent untuk trainingnya\n",
    "mlnn.trainf = nl.train.train_gd\n",
    "\n",
    "error_progress = mlnn.train(data, label, epochs=2000, show=100, goal=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediksi pakai datanya sendiri\n",
    "output = mlnn.sim(data)\n",
    "y_pred = output.reshape(jumlah_titik)\n",
    "\n",
    "# dense layer\n",
    "x_dense = np.linspace(nilai_min, nilai_maks, jumlah_titik*2)\n",
    "y_dense_pred = mlnn.sim(x_dense.reshape(x_dense.size,1)).reshape(x_dense.size)\n",
    "\n",
    "plt.plot(x_dense, y_dense_pred, '-',label ='dense layer');\n",
    "plt.plot(x, y, '.', label='nilai beneran');\n",
    "plt.plot(x, y_pred, 'p', label='nilai prediksi');\n",
    "plt.title('Beneran vs Prediksi');\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dalam project beneran harus ada pre-processing. Ga simpel kaya di sini. Berdasarkan data yg kita punya dipilih lah model nn yang cocok pada training, tweaking parameter cari yang cocok."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buat data sikuensial. Beda sama data statis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* analysis of sequential data (weather, stock, traffic, video feeds).\n",
    "* suitable for time-series\n",
    "* require more complex architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita ga bisa sembarangan tuh pakai model2 ml sederhana atau pakai aristek nn biasa, karena kita berurusan dengan dependensi temporal dari data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pendefinisian gelombang sinus\n",
    "def dapat_data(jum_titik):\n",
    "    g1 = 0.6 * np.sin(np.arange(0, jum_titik))\n",
    "    g2 = 3.5 * np.sin(np.arange(0, jum_titik))\n",
    "    g3 = 1.2 * np.sin(np.arange(0, jum_titik))\n",
    "    g4 = 4.6 * np.sin(np.arange(0, jum_titik))\n",
    "    \n",
    "    a1 = np.ones(jum_titik)\n",
    "    a2 = 2.2 + np.zeros(jum_titik)\n",
    "    a3 = 3.1 * np.ones(jum_titik)\n",
    "    a4 = 0.9 + np.zeros(jum_titik)\n",
    "    \n",
    "    gelombang = np.array([g1, g2, g3, g4]).reshape(jum_titik*4,1)\n",
    "    amplitudo = np.array([a1, a2, a3, a4]).reshape(jum_titik*4,1)\n",
    "    \n",
    "    return gelombang, amplitudo\n",
    "\n",
    "def visualisasi_output(nn, jum_titik_test):\n",
    "    gelombang, amplitudo = dapat_data(jum_titik_test)\n",
    "    output = nn.sim(gelombang)\n",
    "    plt.plot(amplitudo.reshape(jum_titik_test*4));\n",
    "    plt.plot(output.reshape(jum_titik_test*4));\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    jum_titik = 100\n",
    "    gelombang, amplitudo = dapat_data(jum_titik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elman RNN dengan 2 layers\n",
    "nn = nl.net.newelm([[-2,2]], [10,1], [nl.trans.TanSig(), nl.trans.PureLin()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "min = -2, maks = 2 (input)\n",
    "\n",
    "jumlah perseptron di dua layers: 10,1\n",
    "\n",
    "dua fungsi transfer, yakni tangen hiperbolik dan linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inisilasi fungsi untuk setiap layer\n",
    "nn.layers[0].initf = nl.init.InitRand([-.1, .1], 'wb')\n",
    "nn.layers[1].initf = nl.init.InitRand([-.1, .1], 'wb')\n",
    "\n",
    "# actually initialize the net\n",
    "nn.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_progress = nn.train(gelombang, amplitudo, epochs=2000, show=100, goal=.01)\n",
    "\n",
    "output = nn.sim(gelombang)\n",
    "\n",
    "plt.subplot(211);\n",
    "plt.plot(error_progress);\n",
    "plt.xlabel('Jumlah Epochs');\n",
    "plt.ylabel('Error (MSE)');\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(amplitudo.reshape(jum_titik*4))\n",
    "plt.plot(output.reshape(jum_titik*4))\n",
    "plt.legend(['Asli', 'Prediksi'])\n",
    "\n",
    "plt.figure();\n",
    "plt.subplot(211);\n",
    "visualisasi_output(nn, 150); # untuk bilangan acak di atas jumlah training\n",
    "plt.xlim([0, 300]);\n",
    "\n",
    "plt.subplot(212);\n",
    "visualisasi_output(nn, 50); # untuk bilangan acak di bawah jumlah training\n",
    "plt.xlim([0, 300]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* recognizing hand-writen character images\n",
    "* dataset dari Rob Kassel dari MIT Spoken Language Systems Group yang telah dibersihkan, dinormalisasi, dan dirasterisasi oleh Ben Taskar (lektor kepala di Departemen Ilmu Komputer dan Informatika di Universitas Pennsylvania) ketika yang bersangkutan masih menjadi mahasiswa doktoral di Stanford di bawah supervisi Daphne Koller. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys # standar lib\n",
    "import cv2 # opencv \n",
    "import numpy as np\n",
    "file_input = \"./data/letter.data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'line' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9a7c0872a990>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m                                      \u001b[0mfx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfaktor_resize_gambar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                                      fy=faktor_resize_gambar)\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# display the character\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Gambar'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgambar_terskala\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'line' is not defined"
     ]
    }
   ],
   "source": [
    "# set parameters for data visualization\n",
    "faktor_resize_gambar = 12\n",
    "awal, akhir = 6, -1\n",
    "panjang, lebar = 16, 8\n",
    "\n",
    "# baca setiap baris data dan rescale ke 255 (rgb) hingga kita menghentikan loop pakai ctrl +c\n",
    "# pake list comprehension, untuk memisahkan baris dengan tab\n",
    "# reshape dari array 1 dim ke gambar berdimensi 2 kemudian mengatur skalanya dengan \n",
    "# menggunakan opencv\n",
    "with open(file_input, 'r') as f:\n",
    "    for baris in f.readlines():\n",
    "        data = np.array([255*float(x) for x in baris.split('\\t')[awal:akhir]])\n",
    "        gambar = np.reshape(data, (panjang, lebar))\n",
    "        gambar_terskala = cv2.resize(gambar, None,\n",
    "                                     fx=faktor_resize_gambar, \n",
    "                                     fy=faktor_resize_gambar)\n",
    "        print(line) # display the character\n",
    "        cv2.imshow('Gambar', gambar_terskala)\n",
    "        \n",
    "        c = cv2.waitKey()\n",
    "        if c == 27:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neurolab as nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jumlah titik data yg mau kita load\n",
    "jum_data = 50\n",
    "# define string containing all distinct or different chars and extract the number of class\n",
    "label_ori = 'adgimno'\n",
    "jum_label_ori = len(label_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 90 % train, 10% testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "jum_train = int(.9*jum_data)\n",
    "jum_test = jum_data - jum_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ekstraksi parameter\n",
    "awal = 6\n",
    "akhir = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [] # fitur\n",
    "labels = [] # label\n",
    "\n",
    "with open(file_input, 'r') as f:\n",
    "    for baris in f.readlines():\n",
    "        nilai = baris.split('\\t')\n",
    "        if nilai[1] not in label_ori:\n",
    "            continue\n",
    "        label = np.zeros((jum_label_ori,1))\n",
    "        label[label_ori.index(nilai[1])] = 1\n",
    "        labels.append(label)\n",
    "        \n",
    "        karakter_saat_ini = np.array([float(x) for x in nilai[awal:akhir]])\n",
    "        data.append(karakter_saat_ini)\n",
    "        \n",
    "        if len(data) >= jum_data:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert labels and data to np array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(labels), type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data) # float type array\n",
    "labels = np.array(labels).reshape(jum_data, jum_label_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of dimension that match our need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "jum_dim = len(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.60 GiB for an array with shape (18695, 18695) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e10992b17436>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m error_progress = nn.train(data[:jum_train, :], labels[:jum_train, :], \n\u001b[0;32m----> 8\u001b[0;31m                           epochs = 10000, show = 1000, goal=.01)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/neurolab/core.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \"\"\"\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/neurolab/core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, net, input, target, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTrainStop\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'show'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/neurolab/train/spo.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, net, input, target)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         x = fmin_bfgs(self.fcn, self.x.copy(), fprime=self.grad, callback=self.step,\n\u001b[0;32m---> 79\u001b[0;31m                       **self.kwargs)\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfmin_bfgs\u001b[0;34m(f, x0, fprime, args, gtol, norm, epsilon, maxiter, full_output, disp, retall, callback)\u001b[0m\n\u001b[1;32m    950\u001b[0m             'return_all': retall}\n\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_minimize_bfgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfprime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_minimize_bfgs\u001b[0;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, **unknown_options)\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdisp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Divide-by-zero encountered: rhok assumed large\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1067\u001b[0;31m         \u001b[0mA1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mI\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0myk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrhok\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1068\u001b[0m         \u001b[0mA2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mI\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0myk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrhok\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m         Hk = numpy.dot(A1, numpy.dot(Hk, A2)) + (rhok * sk[:, numpy.newaxis] *\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 2.60 GiB for an array with shape (18695, 18695) and data type float64"
     ]
    }
   ],
   "source": [
    "# feed forward nn and train it with gradien descent\n",
    "nn = nl.net.newff([[0,1] for _ in range(len(data[0]))], [128,16, jum_label_ori])\n",
    "\n",
    "# set train using gradien descent\n",
    "nn.traind = nl.train.train_gd\n",
    "\n",
    "error_progress = nn.train(data[:jum_train, :], labels[:jum_train, :], \n",
    "                          epochs = 10000, show = 1000, goal=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
